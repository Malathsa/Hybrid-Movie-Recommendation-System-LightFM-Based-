{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Imports =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, auc_score, recall_at_k\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7517f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings data: (100836, 4)\n",
      "Movies data: (9742, 3)\n",
      "Tags data: (3683, 4)\n"
     ]
    }
   ],
   "source": [
    "# ===== 2) Load Data =====\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "tags = pd.read_csv(\"tags.csv\")\n",
    "\n",
    "print(f\"Ratings data: {ratings.shape}\")\n",
    "print(f\"Movies data: {movies.shape}\")\n",
    "print(f\"Tags data: {tags.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a435cf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä BIAS DETECTION - Major-Minor Ratio\n",
      "============================================================\n",
      "üé≠ Genre Counts (Top 10):\n",
      "Drama        4361\n",
      "Comedy       3756\n",
      "Thriller     1894\n",
      "Action       1828\n",
      "Romance      1596\n",
      "Adventure    1263\n",
      "Crime        1199\n",
      "Sci-Fi        980\n",
      "Horror        978\n",
      "Fantasy       779\n",
      "dtype: int64\n",
      "\n",
      "üìâ Genre Counts (Bottom 10):\n",
      "Film-Noir       87\n",
      "IMAX           158\n",
      "Western        167\n",
      "Musical        334\n",
      "War            382\n",
      "Documentary    440\n",
      "Mystery        573\n",
      "Animation      611\n",
      "Children       664\n",
      "Fantasy        779\n",
      "dtype: int64\n",
      "\n",
      "üü¶ Major‚ÄìMinor Ratio: 50.13\n",
      "Most common genre has: 4361 movies\n",
      "Least common genre has: 87 movies\n",
      "‚ö†Ô∏è Warning: Strong genre imbalance detected!\n"
     ]
    }
   ],
   "source": [
    "# ===== 3) Detect Bias =====\n",
    "def major_minor_ratio_genres(movies_df):\n",
    "    movies_df = movies_df.copy()\n",
    "    movies_df[\"genres\"] = movies_df[\"genres\"].str.split(\"|\")\n",
    "    \n",
    "    genre_counts = {}\n",
    "    for genre_list in movies_df[\"genres\"]:\n",
    "        if isinstance(genre_list, list):\n",
    "            for g in genre_list:\n",
    "                if g != \"(no genres listed)\":\n",
    "                    genre_counts[g] = genre_counts.get(g, 0) + 1\n",
    "    \n",
    "    genre_counts = pd.Series(genre_counts)\n",
    "    \n",
    "    major = genre_counts.max()\n",
    "    minor = genre_counts.min()\n",
    "    ratio = major / minor\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä BIAS DETECTION - Major-Minor Ratio\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"üé≠ Genre Counts (Top 10):\")\n",
    "    print(genre_counts.sort_values(ascending=False).head(10))\n",
    "    print(\"\\nüìâ Genre Counts (Bottom 10):\")\n",
    "    print(genre_counts.sort_values().head(10))\n",
    "    \n",
    "    print(f\"\\nüü¶ Major‚ÄìMinor Ratio: {ratio:.2f}\")\n",
    "    print(f\"Most common genre has: {major} movies\")\n",
    "    print(f\"Least common genre has: {minor} movies\")\n",
    "    \n",
    "    if ratio > 10:\n",
    "        print(\"‚ö†Ô∏è Warning: Strong genre imbalance detected!\")\n",
    "    else:\n",
    "        print(\"‚úÖ Genre distribution is reasonably balanced.\")\n",
    "    \n",
    "    return ratio, genre_counts\n",
    "\n",
    "ratio, genre_counts = major_minor_ratio_genres(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c7b8308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚öñÔ∏è  APPLYING IDF-BASED REWEIGHTING\n",
      "============================================================\n",
      "\n",
      "Genre Weights (IDF):\n",
      "\n",
      "Top 5 Highest Weights (rare genres - boosted):\n",
      "   Film-Noir           : weight=4.715 (appears in 87 movies)\n",
      "   IMAX                : weight=4.118 (appears in 158 movies)\n",
      "   Western             : weight=4.063 (appears in 167 movies)\n",
      "   Musical             : weight=3.370 (appears in 334 movies)\n",
      "   War                 : weight=3.235 (appears in 382 movies)\n",
      "\n",
      "Top 5 Lowest Weights (common genres - reduced):\n",
      "   Romance             : weight=1.805 (appears in 1596 movies)\n",
      "   Action              : weight=1.670 (appears in 1828 movies)\n",
      "   Thriller            : weight=1.634 (appears in 1894 movies)\n",
      "   Comedy              : weight=0.950 (appears in 3756 movies)\n",
      "   Drama               : weight=0.800 (appears in 4361 movies)\n"
     ]
    }
   ],
   "source": [
    "# ===== 4) Calculate IDF Weights =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚öñÔ∏è  APPLYING IDF-BASED REWEIGHTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_movies = len(movies[movies['genres'] != \"(no genres listed)\"])\n",
    "genre_weights = {}\n",
    "\n",
    "for genre, count in genre_counts.items():\n",
    "    idf_weight = np.log(total_movies / count)\n",
    "    genre_weights[genre] = idf_weight\n",
    "\n",
    "print(\"\\nGenre Weights (IDF):\")\n",
    "sorted_weights = sorted(genre_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop 5 Highest Weights (rare genres - boosted):\")\n",
    "for genre, weight in sorted_weights[:5]:\n",
    "    count = genre_counts[genre]\n",
    "    print(f\"   {genre:20s}: weight={weight:.3f} (appears in {count} movies)\")\n",
    "\n",
    "print(\"\\nTop 5 Lowest Weights (common genres - reduced):\")\n",
    "for genre, weight in sorted_weights[-5:]:\n",
    "    count = genre_counts[genre]\n",
    "    print(f\"   {genre:20s}: weight={weight:.3f} (appears in {count} movies)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7866cbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique genres: 19\n",
      "Top 50 tags: ['In Netflix queue', 'atmospheric', 'thought-provoking', 'superhero', 'funny', 'surreal', 'Disney', 'religion', 'sci-fi', 'quirky']...\n",
      "\n",
      "============================================================\n",
      "DATASET PREPARATION\n",
      "============================================================\n",
      "Total ratings: 100836\n",
      "Positive ratings (>= 4.0): 48580\n",
      "Unique users: 610\n",
      "Unique movies in ratings: 9724\n",
      "Movies common to both ratings and movies: 9724\n"
     ]
    }
   ],
   "source": [
    "# ===== 5) Prepare Content Features =====\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "all_genres = set()\n",
    "for genre_list in movies['genres']:\n",
    "    if isinstance(genre_list, list):\n",
    "        for genre in genre_list:\n",
    "            if genre != \"(no genres listed)\":\n",
    "                all_genres.add(genre)\n",
    "\n",
    "top_tags = tags['tag'].value_counts().head(50).index.tolist()\n",
    "print(f\"\\nTotal unique genres: {len(all_genres)}\")\n",
    "print(f\"Top 50 tags: {top_tags[:10]}...\")\n",
    "\n",
    "# ===== 6) Prepare Dataset =====\n",
    "RATING_THRESHOLD = 4.0\n",
    "positive = ratings[ratings[\"rating\"] >= RATING_THRESHOLD].copy()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DATASET PREPARATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total ratings: {len(ratings)}\")\n",
    "print(f\"Positive ratings (>= {RATING_THRESHOLD}): {len(positive)}\")\n",
    "\n",
    "all_users = ratings[\"userId\"].unique()\n",
    "all_items = ratings[\"movieId\"].unique()\n",
    "\n",
    "print(f\"Unique users: {len(all_users)}\")\n",
    "print(f\"Unique movies in ratings: {len(all_items)}\")\n",
    "\n",
    "movies_in_ratings = movies[movies['movieId'].isin(all_items)]\n",
    "print(f\"Movies common to both ratings and movies: {len(movies_in_ratings)}\")\n",
    "\n",
    "# Create Dataset\n",
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    users=all_users,\n",
    "    items=all_items,\n",
    "    item_features=list(all_genres) + top_tags\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36cabc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Built weighted features for 9724 movies\n"
     ]
    }
   ],
   "source": [
    "# ===== 7) Build Interactions with Weighted Features =====\n",
    "def prepare_features_with_reweighting(genre_weights, reweight_strength=1.0):\n",
    "    \"\"\"\n",
    "    Build item features with genre reweighting\n",
    "    \n",
    "    Args:\n",
    "        genre_weights: Dictionary of genre weights\n",
    "        reweight_strength: Controls the strength of reweighting (0=no reweight, 1=full reweight)\n",
    "    \"\"\"\n",
    "    # Build interactions\n",
    "    interactions, _ = dataset.build_interactions(\n",
    "        [(row.userId, row.movieId) for row in positive.itertuples(index=False)]\n",
    "    )\n",
    "    \n",
    "    # Build weighted item features - USE DICTIONARY FORMAT\n",
    "    item_features_list = []\n",
    "    \n",
    "    for movie_id in all_items:\n",
    "        movie_genres = movies[movies['movieId'] == movie_id]['genres']\n",
    "        \n",
    "        weighted_features = {}  # Dictionary for weighted features\n",
    "        if len(movie_genres) > 0:\n",
    "            genres_str = movie_genres.iloc[0]\n",
    "            if isinstance(genres_str, list):\n",
    "                for genre in genres_str:\n",
    "                    if genre != \"(no genres listed)\":\n",
    "                        # Apply genre weight\n",
    "                        base_weight = genre_weights.get(genre, 1.0)\n",
    "                        # Apply reweight strength\n",
    "                        weight = 1.0 + (base_weight - 1.0) * reweight_strength\n",
    "                        # CORRECT FORMAT: dictionary {feature_name: weight}\n",
    "                        weighted_features[genre] = weight\n",
    "        \n",
    "        item_features_list.append((movie_id, weighted_features))\n",
    "    \n",
    "    print(f\"‚úÖ Built weighted features for {len(item_features_list)} movies\")\n",
    "    \n",
    "    item_features_matrix = dataset.build_item_features(item_features_list)\n",
    "    \n",
    "    return interactions, item_features_matrix\n",
    "\n",
    "# Build features with reweighting\n",
    "interactions, item_features = prepare_features_with_reweighting(\n",
    "    genre_weights, \n",
    "    reweight_strength=0.7  # Adjust this value: 0=no reweight, 1=full reweight\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f068db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Final check:\n",
      "   all_items: 9724 movies\n",
      "   item_features: 9724 rows\n",
      "   Match: True\n",
      "‚úÖ READY FOR HYBRID RECOMMENDATIONS!\n"
     ]
    }
   ],
   "source": [
    "# ===== 8) Final check =====\n",
    "print(f\"\\nüîç Final check:\")\n",
    "print(f\"   all_items: {len(all_items)} movies\")\n",
    "print(f\"   item_features: {item_features.shape[0]} rows\")\n",
    "print(f\"   Match: {len(all_items) == item_features.shape[0]}\")\n",
    "\n",
    "if len(all_items) == item_features.shape[0]:\n",
    "    print(\"‚úÖ READY FOR HYBRID RECOMMENDATIONS!\")\n",
    "else:\n",
    "    print(\"‚ùå NEED TO FIX ITEM FEATURES!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e32e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data: 38864 interactions\n",
      "Testing data: 9716 interactions\n",
      "Testing data after filtering: 9142 interactions\n",
      "Train interactions shape: (610, 9724)\n",
      "Test interactions shape: (610, 9724)\n",
      "Item features shape: (9724, 9793)\n"
     ]
    }
   ],
   "source": [
    "# ===== 9) Split Data =====\n",
    "train_df, test_df = train_test_split(\n",
    "    positive,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining data: {len(train_df)} interactions\")\n",
    "print(f\"Testing data: {len(test_df)} interactions\")\n",
    "\n",
    "# Ensure test data exists in training\n",
    "train_users = set(train_df[\"userId\"].unique())\n",
    "train_items = set(train_df[\"movieId\"].unique())\n",
    "test_df = test_df[\n",
    "    test_df[\"userId\"].isin(train_users) & \n",
    "    test_df[\"movieId\"].isin(train_items)\n",
    "].copy()\n",
    "\n",
    "print(f\"Testing data after filtering: {len(test_df)} interactions\")\n",
    "\n",
    "def prepare_interactions(df):\n",
    "    return dataset.build_interactions(\n",
    "        [(row.userId, row.movieId) for row in df.itertuples(index=False)]\n",
    "    )[0]\n",
    "\n",
    "train = prepare_interactions(train_df)\n",
    "test = prepare_interactions(test_df)\n",
    "\n",
    "print(f\"Train interactions shape: {train.shape}\")\n",
    "print(f\"Test interactions shape: {test.shape}\")\n",
    "print(f\"Item features shape: {item_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "badfd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 10) Evaluation Function =====\n",
    "def evaluate_model(model, train_interactions, test_interactions, item_features, k=10):\n",
    "    # On training data\n",
    "    prec_tr = precision_at_k(model, train_interactions, item_features=item_features, \n",
    "                             k=k, num_threads=1).mean()\n",
    "    auc_tr = auc_score(model, train_interactions, item_features=item_features, \n",
    "                       num_threads=1).mean()\n",
    "    rec_tr = recall_at_k(model, train_interactions, item_features=item_features,\n",
    "                         k=k, num_threads=1).mean()   # ‚¨ÖÔ∏è (ÿ≥ÿ∑ÿ± ÿ¨ÿØŸäÿØ) Recall@k ÿπŸÑŸâ ÿßŸÑÿ™ÿØÿ±Ÿäÿ®\n",
    "\n",
    "    # On test data\n",
    "    prec_te = precision_at_k(model, test_interactions, train_interactions=train_interactions,\n",
    "                             item_features=item_features, k=k, num_threads=1).mean()\n",
    "    auc_te = auc_score(model, test_interactions, train_interactions=train_interactions,\n",
    "                       item_features=item_features, num_threads=1).mean()\n",
    "    rec_te = recall_at_k(model, test_interactions, train_interactions=train_interactions,\n",
    "                         item_features=item_features, k=k, num_threads=1).mean()  # ‚¨ÖÔ∏è (ÿ≥ÿ∑ÿ± ÿ¨ÿØŸäÿØ) Recall@k ÿπŸÑŸâ ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ±\n",
    "\n",
    "    print(f\"Precision@{k}: train {prec_tr:.4f} ({prec_tr*100:.2f}%), \"\n",
    "          f\"test {prec_te:.4f} ({prec_te*100:.2f}%)\")\n",
    "    print(f\"Recall@{k}:    train {rec_tr:.4f} ({rec_tr*100:.2f}%), \"\n",
    "          f\"test {rec_te:.4f} ({rec_te*100:.2f}%)  (Recommendation Accuracy)\")  # ‚¨ÖÔ∏è (ÿ≥ÿ∑ÿ± ÿ¨ÿØŸäÿØ ŸÑŸÑÿ∑ÿ®ÿßÿπÿ©)\n",
    "    print(f\"AUC:           train {auc_tr:.4f}, test {auc_te:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2fee4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Hybrid Model Training (WARP + IDF-Weighted Genres)\n",
      "==================================================\n",
      "Precision@10: train 0.2995 (29.95%), test 0.1166 (11.66%)\n",
      "Recall@10:    train 0.0850 (8.50%), test 0.0963 (9.63%)  (Recommendation Accuracy)\n",
      "AUC:           train 0.9489, test 0.9310\n",
      "üíæ Saved model checkpoint to 'lightfm_hybrid_checkpoint.pkl'\n"
     ]
    }
   ],
   "source": [
    "# ===== 11) Train Hybrid Model =====\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Hybrid Model Training (WARP + IDF-Weighted Genres)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model_hybrid = LightFM(\n",
    "    loss=\"warp\",\n",
    "    learning_rate=0.05,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train with IDF-weighted content features\n",
    "model_hybrid.fit(\n",
    "    train,\n",
    "    item_features=item_features,\n",
    "    epochs=15,\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "# Evaluate hybrid model\n",
    "evaluate_model(model_hybrid, train, test, item_features, k=10)\n",
    "\n",
    "# ===== 11a) Save Model Checkpoint =====\n",
    "with open(\"lightfm_hybrid_checkpoint.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_hybrid, f)\n",
    "\n",
    "print(\"üíæ Saved model checkpoint to 'lightfm_hybrid_checkpoint.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65a84dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ HYBRID RECOMMENDATIONS (IDF-Weighted)\n",
      "============================================================\n",
      "üìä Hybrid predictions for 9724 movies\n",
      "\n",
      "üîç Generating recommendations for user 1...\n",
      "üé¨ User 1 - Top 5 Hybrid Recommendations:\n",
      "   1. Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "      ‚≠ê Score: -0.484 | üé≠ ['Action', 'Adventure']\n",
      "   2. Shawshank Redemption, The (1994)\n",
      "      ‚≠ê Score: -0.569 | üé≠ ['Crime', 'Drama']\n",
      "   3. Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
      "      ‚≠ê Score: -0.674 | üé≠ ['Adventure', 'Fantasy']\n",
      "   4. Matrix, The (1999)\n",
      "      ‚≠ê Score: -0.773 | üé≠ ['Action', 'Sci-Fi', 'Thriller']\n",
      "   5. Lord of the Rings: The Two Towers, The (2002)\n",
      "      ‚≠ê Score: -0.785 | üé≠ ['Adventure', 'Fantasy']\n",
      "‚è± Response time for user 1: 2.247 seconds\n",
      "\n",
      "üîç Generating recommendations for user 2...\n",
      "üé¨ User 2 - Top 5 Hybrid Recommendations:\n",
      "   1. Shawshank Redemption, The (1994)\n",
      "      ‚≠ê Score: 1.597 | üé≠ ['Crime', 'Drama']\n",
      "   2. Pulp Fiction (1994)\n",
      "      ‚≠ê Score: 1.401 | üé≠ ['Comedy', 'Crime', 'Drama', 'Thriller']\n",
      "   3. Godfather, The (1972)\n",
      "      ‚≠ê Score: 1.350 | üé≠ ['Crime', 'Drama']\n",
      "   4. Clerks (1994)\n",
      "      ‚≠ê Score: 1.184 | üé≠ ['Comedy']\n",
      "   5. Silence of the Lambs, The (1991)\n",
      "      ‚≠ê Score: 1.180 | üé≠ ['Crime', 'Horror', 'Thriller']\n",
      "‚è± Response time for user 2: 2.234 seconds\n",
      "\n",
      "üîç Generating recommendations for user 3...\n",
      "üé¨ User 3 - Top 5 Hybrid Recommendations:\n",
      "   1. Terminator 2: Judgment Day (1991)\n",
      "      ‚≠ê Score: 1.522 | üé≠ ['Action', 'Sci-Fi']\n",
      "   2. Alien (1979)\n",
      "      ‚≠ê Score: 1.458 | üé≠ ['Horror', 'Sci-Fi']\n",
      "   3. Matrix, The (1999)\n",
      "      ‚≠ê Score: 1.370 | üé≠ ['Action', 'Sci-Fi', 'Thriller']\n",
      "   4. Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "      ‚≠ê Score: 1.337 | üé≠ ['Action', 'Adventure', 'Sci-Fi']\n",
      "   5. Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "      ‚≠ê Score: 1.256 | üé≠ ['Action', 'Adventure', 'Sci-Fi']\n",
      "‚è± Response time for user 3: 2.245 seconds\n"
     ]
    }
   ],
   "source": [
    "# ===== 12) Generate Sample Recommendations =====\n",
    "def sample_recommendations(model, user_ids, item_features, dataset, n_items=5):\n",
    "    \"\"\"Generate movie recommendations using hybrid model with proper ID mapping\"\"\"\n",
    "    \n",
    "    user_id_map, user_feature_map, item_id_map, item_feature_map = dataset.mapping()\n",
    "    \n",
    "    available_movies = list(item_id_map.values())\n",
    "    print(f\"üìä Hybrid predictions for {len(available_movies)} movies\")\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        print(f\"\\nüîç Generating recommendations for user {user_id}...\")\n",
    "        user_start = time.time()\n",
    "        \n",
    "        user_internal_id = user_id_map.get(user_id)\n",
    "        if user_internal_id is None:\n",
    "            print(f\"‚ùå User {user_id} not found in dataset\")\n",
    "            continue\n",
    "        \n",
    "        scores = []\n",
    "        original_movie_ids = []\n",
    "        \n",
    "        for movie_internal_id in available_movies:\n",
    "            score = model.predict(\n",
    "                np.array([user_internal_id], dtype=np.int32), \n",
    "                np.array([movie_internal_id], dtype=np.int32),\n",
    "                item_features=item_features,\n",
    "                num_threads=1\n",
    "            )[0]\n",
    "            scores.append(score)\n",
    "            \n",
    "            original_id = [k for k, v in item_id_map.items() if v == movie_internal_id][0]\n",
    "            original_movie_ids.append(original_id)\n",
    "        \n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        # Get top recommendations\n",
    "        top_indices = np.argsort(-scores)[:n_items]\n",
    "        top_movies = []\n",
    "        \n",
    "        for idx in top_indices:\n",
    "            original_movie_id = original_movie_ids[idx]\n",
    "            movie_data = movies[movies['movieId'] == original_movie_id]\n",
    "            if len(movie_data) > 0:\n",
    "                title = movie_data['title'].values[0]\n",
    "                genres = movie_data['genres'].values[0]\n",
    "                top_movies.append((title, genres, scores[idx]))\n",
    "        \n",
    "        print(f\"üé¨ User {user_id} - Top {n_items} Hybrid Recommendations:\")\n",
    "        for i, (title, genres, score) in enumerate(top_movies, 1):\n",
    "            print(f\"   {i}. {title}\")\n",
    "            print(f\"      ‚≠ê Score: {score:.3f} | üé≠ {genres}\")\n",
    "        user_elapsed = time.time() - user_start\n",
    "        print(f\"‚è± Response time for user {user_id}: {user_elapsed:.3f} seconds\")\n",
    "\n",
    "\n",
    "# Show recommendations for first 3 users\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ HYBRID RECOMMENDATIONS (IDF-Weighted)\")\n",
    "print(\"=\"*60)\n",
    "sample_users = list(all_users)[:3]\n",
    "sample_recommendations(model_hybrid, sample_users, item_features, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f101f-0895-4f3d-abc9-3fcbb9e71cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
